{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Nuclei Classifier Model from Extracted Feature Data\n",
    "\n",
    "In this comprehensive tutorial, we will guide you through the process of constructing a nuclei classifier using the powerful *Random Forest* algorithm. Our approach involves extracting features from image data using DSA and assigning classes to the data instances using K-Means method. A foundational grasp of Python and familiarity with utilizing iPython notebooks are prerequisites for comprehending the content presented in this tutorial.\n",
    "\n",
    "**Included Resources**\n",
    "- [Input Image](https://data.kitware.com/api/v1/file/hashsum/sha512/1ff135eb0ff8864a876a19ae3dec579f27f1718726a68643f6a40a244fdfa08e81f63f1413c198b38384cb34e8705bc60a6c69ef2b706cb0419f6ec091b2b621/download)\n",
    "- [Extracted Features file (Optional)](https://data.kitware.com/api/v1/file/hashsum/sha512/e8c829b60d316ff84d2ffafb5accd605eb8dcd02dec709105ec9127aa2d7969e2feca74f66394b26f0e90375cd0d1cda3d1831023449f66cf50a637906444578/download)\n",
    "\n",
    "*This tutorial is created by Subin Erattakulangara (Kitware)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 (Extract nuclei features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the Nuclei Feature extraction panel in DSA. and upload the image data into *Input Image* area shown below. Provide the location for both feature file and annotation files to be saved. Then press submit to start the process.The cli will generate the feature file requried for the classifier. Annotation file is not required for creating the classfier.\n",
    "\n",
    "![DSA panel.png](https://data.kitware.com/api/v1/file/hashsum/sha512/10f88a5400e7fa46605e3f75530ae8703a429fbbf1185444a14fa40beec251434d19760de90bdaae25b5ece3557b502b59e40fab377b3df5978088b14c3a14e2/download)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 (Generate training labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the CLI generates the feature file, download it. Create a new folder and put the downloaded feature file in there. Then, run the provided Python code within the same folder. This code enhances the feature file with classes. This simple flow ensures you manage, organize, and improve your feature file effortlessly.<br><br>\n",
    "You can also use the `.csv` file provided above to create the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rad the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file\n",
    "import pandas as pd\n",
    "df = pd.read_csv('<Input feature filename>.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standardize the data and perform K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "X = df.values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Perform KMeans clustering\n",
    "num_clusters = 5  # Number of clusters you want to create\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(X_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add generated cluster labels to feature file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster labels to the original data\n",
    "df['Cluster'] = cluster_labels\n",
    "\n",
    "# Print the count of data points in each cluster\n",
    "print(df['Cluster'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this process we have modified the feature file so that the class labels are also added into it. These labels are required to train the Random forest classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 (Train random forest classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert dataframe to target and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the last column contains the target labels\n",
    "X = df.iloc[:, :-1]  # Features\n",
    "y = df.iloc[:, -1]   # Target labels\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# Convert categorical labels to numerical using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Convert numerical predictions back to categorical labels\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the trained model into a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = '<output file name>.pkl'\n",
    "with open(model_filename, 'wb') as model_file:\n",
    "    pickle.dump(classifier, model_file)\n",
    "\n",
    "print(f\"Model saved as {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This trained model can be used for nuclei classfication - [link to the nuclei classification tutorial]()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiffexp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
